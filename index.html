<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <title>Stair Detector - Live</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
      background: #111;
      color: #eee;
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    h1 {
      font-size: 20px;
      text-align: center;
      margin: 10px 0 5px 0;
    }
    #videoContainer {
      position: relative;
      width: 100%;
      max-width: 480px;
      margin-top: 5px;
    }
    #videoElement {
      width: 100%;
      border: 1px solid #444;
      border-radius: 4px;
      background: #000;
    }
    #overlayCanvas {
      position: absolute;
      left: 0;
      top: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
    }
    #info {
      margin-top: 8px;
      font-size: 14px;
      text-align: center;
    }
    #status {
      margin-top: 4px;
      font-size: 12px;
      text-align: center;
      color: #ccc;
    }
    #controls {
      margin-top: 6px;
      display: flex;
      gap: 8px;
      justify-content: center;
    }
    button {
      padding: 6px 10px;
      font-size: 14px;
      border-radius: 4px;
      border: none;
      background: #2b7cff;
      color: white;
      cursor: pointer;
    }
    button:disabled {
      background: #555;
      cursor: default;
    }
  </style>
</head>
<body>

<h1>Stair Detector – Live</h1>

<div id="videoContainer">
  <video id="videoElement" autoplay playsinline muted></video>
  <canvas id="overlayCanvas"></canvas>
</div>

<div id="controls">
  <button id="startBtn">Démarrer</button>
  <button id="stopBtn" disabled>Arrêter</button>
</div>

<div id="info">En attente de la caméra…</div>
<div id="status"></div>

<script>
  // === Paramètres Roboflow / projet ===
  const API_KEY = "Hl9oVZ2Lmd7lwCSsjCU5";
  const API_URL = "https://serverless.roboflow.com/gildas-lkqed/workflows/custom-workflow-2";

  // ✅ Perf mobile (ajustables)
  const FRAME_INTERVAL_MS = 350; // ~3 FPS (plus rapide si tu diminues)
  const TARGET_W = 640;          // downscale (accélère sur téléphone)
  const JPEG_QUALITY = 0.7;      // 0.6–0.8 recommandé
  const MIN_CONF = 0.4;

  const video = document.getElementById("videoElement");
  const overlay = document.getElementById("overlayCanvas");
  const ctx = overlay.getContext("2d");
  const infoDiv = document.getElementById("info");
  const statusDiv = document.getElementById("status");
  const startBtn = document.getElementById("startBtn");
  const stopBtn = document.getElementById("stopBtn");

  let stream = null;
  let intervalId = null;
  let isBusy = false;

  // --- Anti-clignotement (amélioré) ---
  let previousDetections = [];
  const persistenceFrames = 4;
  let persistenceCounter = 0;

  function avgConf(preds) {
    if (!preds || preds.length === 0) return 0;
    return preds.reduce((a, p) => a + (p.confidence || 0), 0) / preds.length;
  }

  // ✅ Canvas réutilisé (ne pas recréer à chaque frame)
  const tmpCanvas = document.createElement("canvas");
  const tmpCtx = tmpCanvas.getContext("2d");

  // === 1. Appel API Roboflow ===
  async function callWorkflowWithBase64(imageBase64) {
    const payload = {
      api_key: API_KEY,
      inputs: {
        image: { type: "base64", value: imageBase64 }
      }
    };

    const resp = await fetch(API_URL, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(payload)
    });

    if (!resp.ok) {
      const text = await resp.text();
      throw new Error("Erreur API: " + resp.status + " " + text);
    }
    return await resp.json();
  }

  // === 2. find_predictions ===
  function findPredictions(obj) {
    if (!obj) return null;
    if (Array.isArray(obj)) {
      for (const item of obj) {
        const res = findPredictions(item);
        if (res) return res;
      }
    } else if (typeof obj === "object") {
      if (Array.isArray(obj.predictions)) return obj.predictions;
      for (const key in obj) {
        const res = findPredictions(obj[key]);
        if (res) return res;
      }
    }
    return null;
  }

  // === 3. Catégorie de distance ===
  function distanceCategory(boxHeight, imageHeight) {
    const ratio = boxHeight / imageHeight;
    if (ratio < 0.10) return "loin";
    else if (ratio < 0.25) return "moyen";
    else return "proche";
  }

  // === 4. Filtre anti-faux positifs (crosswalk + bandes + bruit) ===
  function filterStairs(rawPreds, imgW, imgH, minConf = 0.4) {
    const raw = (rawPreds || []).filter(p => (p.confidence || 0) >= minConf);
    if (raw.length === 0) return [];

    // Stats globales (motif passage piéton)
    const ys = raw.map(p => p.y / imgH);
    const hs = raw.map(p => p.height / imgH);
    const ws = raw.map(p => p.width / imgW);

    const minY = Math.min(...ys);
    const maxY = Math.max(...ys);
    const verticalSpan = maxY - minY;

    const avgH = hs.reduce((a, b) => a + b, 0) / hs.length;

    const ratios = raw.map((p, i) => (hs[i] > 1e-6 ? ws[i] / hs[i] : 999));
    const avgRatio = ratios.reduce((a, b) => a + b, 0) / ratios.length;

    const fracLow = ys.filter(y => y > 0.6).length / ys.length;

    const looksLikeCrosswalk =
      raw.length >= 3 &&
      fracLow > 0.8 &&
      verticalSpan < 0.15 &&
      avgH < 0.15 &&
      avgRatio > 4.0;

    if (looksLikeCrosswalk) return [];

    // Filtrage individuel
    return raw.filter(p => {
      const wNorm = p.width / imgW;
      const hNorm = p.height / imgH;
      const yNorm = p.y / imgH;

      // ✅ bruit: trop petit
      const area = wNorm * hNorm;
      if (area < 0.01) return false;

      // ✅ grosse bande en bas
      const ratio = hNorm <= 1e-6 ? 999 : wNorm / hNorm;
      const isBigBand = (wNorm > 0.45 && ratio > 5.0 && yNorm > 0.55);
      if (isBigBand) return false;

      return true;
    });
  }

  // === 5. Caméra ===
  async function startCamera() {
    try {
      stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "environment" },
        audio: false
      });
      video.srcObject = stream;
      infoDiv.textContent = "Caméra en direct. Clique sur 'Démarrer' pour analyser.";
      statusDiv.textContent = "";
    } catch (err) {
      console.error(err);
      infoDiv.textContent = "Impossible d'accéder à la caméra.";
      statusDiv.textContent = err.message;
    }
  }

  function stopCamera() {
    if (stream) {
      stream.getTracks().forEach(t => t.stop());
      stream = null;
    }
    video.srcObject = null;
  }

  // === 6. Boucle d'analyse ===
  async function processFrameLoop() {
    if (!video.videoWidth || !video.videoHeight) return;
    if (isBusy) return;
    isBusy = true;

    try {
      // Overlay à la taille vidéo
      overlay.width = video.videoWidth;
      overlay.height = video.videoHeight;

      // ✅ Downscale pour l'API (accélère)
      const vw = video.videoWidth;
      const vh = video.videoHeight;
      const scale = Math.min(1, TARGET_W / vw);

      tmpCanvas.width = Math.round(vw * scale);
      tmpCanvas.height = Math.round(vh * scale);
      tmpCtx.drawImage(video, 0, 0, tmpCanvas.width, tmpCanvas.height);

      const dataURL = tmpCanvas.toDataURL("image/jpeg", JPEG_QUALITY);
      const base64Data = dataURL.split(",")[1];

      const json = await callWorkflowWithBase64(base64Data);
      const preds = findPredictions(json) || [];

      const imgW = tmpCanvas.width;
      const imgH = tmpCanvas.height;

      // Filtre + anti-clignotement intelligent
      let filtered = filterStairs(preds, imgW, imgH, MIN_CONF);

      if (filtered.length === 0) {
        // ✅ persister seulement si l'ancienne détection était fiable
        if (persistenceCounter < persistenceFrames && avgConf(previousDetections) >= 0.6) {
          filtered = previousDetections;
          persistenceCounter++;
        } else {
          previousDetections = [];
        }
      } else {
        previousDetections = filtered;
        persistenceCounter = 0;
      }

      // Dessin
      ctx.clearRect(0, 0, overlay.width, overlay.height);
      ctx.lineWidth = 2;
      ctx.font = "14px Arial";

      // ⚠️ rescale boxes (car on a downscale pour l'API)
      const sx = overlay.width / imgW;
      const sy = overlay.height / imgH;

      let countTotal = 0;
      let countLoin = 0;
      let countMoyen = 0;
      let countProche = 0;

      for (const p of filtered) {
        const conf = p.confidence || 0.0;
        const cls = p.class || "stair";

        const x = p.x * sx;
        const y = p.y * sy;
        const w = p.width * sx;
        const h = p.height * sy;

        const x1 = Math.round(x - w / 2);
        const y1 = Math.round(y - h / 2);
        const x2 = Math.round(x + w / 2);
        const y2 = Math.round(y + h / 2);

        // distance basée sur taille dans l'image API (imgH)
        const cat = distanceCategory(p.height, imgH);

        countTotal++;
        if (cat === "loin") countLoin++;
        else if (cat === "moyen") countMoyen++;
        else countProche++;

        ctx.strokeStyle = "lime";
        ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);

        const label = `${cls} ${conf.toFixed(2)} ${cat}`;
        ctx.fillStyle = "lime";
        ctx.fillText(label, x1 + 2, Math.max(y1 - 4, 12));
      }

      infoDiv.textContent = `Marches: ${countTotal} (loin:${countLoin} moy:${countMoyen} proche:${countProche})`;
      statusDiv.textContent = `Dernière mise à jour: ${new Date().toLocaleTimeString()}`;

    } catch (err) {
      console.error(err);
      statusDiv.textContent = "Erreur: " + err.message;
    } finally {
      isBusy = false;
    }
  }

  // === 7. Boutons ===
  startBtn.addEventListener("click", () => {
    if (!stream) {
      startCamera().then(() => {
        intervalId = setInterval(processFrameLoop, FRAME_INTERVAL_MS);
        startBtn.disabled = true;
        stopBtn.disabled = false;
        infoDiv.textContent = "Analyse en cours…";
      });
    } else {
      intervalId = setInterval(processFrameLoop, FRAME_INTERVAL_MS);
      startBtn.disabled = true;
      stopBtn.disabled = false;
      infoDiv.textContent = "Analyse en cours…";
    }
  });

  stopBtn.addEventListener("click", () => {
    if (intervalId) {
      clearInterval(intervalId);
      intervalId = null;
    }

    stopCamera();

    ctx.clearRect(0, 0, overlay.width, overlay.height);
    infoDiv.textContent = "Caméra arrêtée.";
    statusDiv.textContent = "";

    startBtn.disabled = false;
    stopBtn.disabled = true;

    previousDetections = [];
    persistenceCounter = 0;
  });

  window.addEventListener("load", () => {
    startCamera();
  });
</script>

</body>
</html>
