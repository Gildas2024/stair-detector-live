<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <title>Stair Detector - Live</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
      background: #111;
      color: #eee;
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    h1 {
      font-size: 20px;
      text-align: center;
      margin: 10px 0 5px 0;
    }
    #videoContainer {
      position: relative;
      width: 100%;
      max-width: 480px;
      margin-top: 5px;
    }
    #videoElement {
      width: 100%;
      border: 1px solid #444;
      border-radius: 4px;
      background: #000;
    }
    #overlayCanvas {
      position: absolute;
      left: 0;
      top: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
    }
    #info {
      margin-top: 8px;
      font-size: 14px;
      text-align: center;
    }
    #status {
      margin-top: 4px;
      font-size: 12px;
      text-align: center;
      color: #ccc;
    }
    #controls {
      margin-top: 6px;
      display: flex;
      gap: 8px;
      justify-content: center;
    }
    button {
      padding: 6px 10px;
      font-size: 14px;
      border-radius: 4px;
      border: none;
      background: #2b7cff;
      color: white;
      cursor: pointer;
    }
    button:disabled {
      background: #555;
      cursor: default;
    }
  </style>
</head>
<body>

<h1>Stair Detector – Live</h1>

<div id="videoContainer">
  <video id="videoElement" autoplay playsinline muted></video>
  <canvas id="overlayCanvas"></canvas>
</div>

<div id="controls">
  <button id="startBtn">Démarrer</button>
  <button id="stopBtn" disabled>Arrêter</button>
</div>

<div id="info">En attente de la caméra…</div>
<div id="status"></div>

<script>
  // === Paramètres Roboflow / projet ===
  const API_KEY = "Hl9oVZ2Lmd7lwCSsjCU5";
  const API_URL = "https://serverless.roboflow.com/gildas-lkqed/workflows/custom-workflow-2";
  const FRAME_INTERVAL_MS = 300; // 1 frame toutes les 300 ms
  const MIN_CONF = 0.4;

  const video = document.getElementById("videoElement");
  const overlay = document.getElementById("overlayCanvas");
  const ctx = overlay.getContext("2d");
  const infoDiv = document.getElementById("info");
  const statusDiv = document.getElementById("status");
  const startBtn = document.getElementById("startBtn");
  const stopBtn = document.getElementById("stopBtn");

  let stream = null;
  let intervalId = null;
  let isBusy = false;

  // --- Anti-clignotement : on garde les dernières détections quelques frames ---
  let previousDetections = [];
  let persistenceFrames = 4;   // nombre de frames où on garde les anciennes détections
  let persistenceCounter = 0;

  // === 1. Appel API Roboflow (équivalent de call_workflow_with_frame) ===
  async function callWorkflowWithBase64(imageBase64) {
    const payload = {
      api_key: API_KEY,
      inputs: {
        image: {
          type: "base64",
          value: imageBase64
        }
      }
    };

    const resp = await fetch(API_URL, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(payload)
    });

    if (!resp.ok) {
      const text = await resp.text();
      throw new Error("Erreur API: " + resp.status + " " + text);
    }
    return await resp.json();
  }

  // === 2. find_predictions en version JS ===
  function findPredictions(obj) {
    if (!obj) return null;
    if (Array.isArray(obj)) {
      for (const item of obj) {
        const res = findPredictions(item);
        if (res) return res;
      }
    } else if (typeof obj === "object") {
      if (Array.isArray(obj.predictions)) {
        return obj.predictions;
      }
      for (const key in obj) {
        const res = findPredictions(obj[key]);
        if (res) return res;
      }
    }
    return null;
  }

  // === 3. Catégorie de distance (loin / moyen / proche) ===
  function distanceCategory(boxHeight, imageHeight) {
    const ratio = boxHeight / imageHeight;
    if (ratio < 0.10) return "loin";
    else if (ratio < 0.25) return "moyen";
    else return "proche";
  }

  // === 4. Filtre anti-passage piéton amélioré ===
  function filterStairs(rawPreds, imgW, imgH, minConf = 0.4) {
    // 1) On garde seulement les détections au-dessus du seuil
    const raw = rawPreds.filter(p => (p.confidence || 0) >= minConf);
    if (raw.length === 0) return [];

    // 2) On calcule des stats globales
    const ys = raw.map(p => p.y / imgH);
    const hs = raw.map(p => p.height / imgH);
    const ws = raw.map(p => p.width / imgW);

    const minY = Math.min(...ys);
    const maxY = Math.max(...ys);
    const verticalSpan = maxY - minY;

    const avgH = hs.reduce((a, b) => a + b, 0) / hs.length;
    const avgW = ws.reduce((a, b) => a + b, 0) / ws.length;

    // Largeur/hauteur moyenne (plus c'est grand, plus c'est une bande plate)
    const ratios = [];
    for (let i = 0; i < raw.length; i++) {
      if (hs[i] > 1e-6) {
        ratios.push(ws[i] / hs[i]);
      }
    }
    const avgRatio = ratios.length
      ? ratios.reduce((a, b) => a + b, 0) / ratios.length
      : 0;

    const fracLow = ys.filter(y => y > 0.6).length / ys.length;

    // 3) Motif "passage piéton" global :
    // - plusieurs bandes
    // - presque toutes en bas
    // - peu d'étalement vertical
    // - boîtes fines
    // - très larges / hauteur
    const looksLikeCrosswalk =
      raw.length >= 3 &&
      fracLow > 0.8 &&        // > 80% en bas
      verticalSpan < 0.15 &&  // très peu de différence en hauteur
      avgH < 0.15 &&          // boîtes plutôt fines
      avgRatio > 4.0;         // très larges par rapport à la hauteur

    if (looksLikeCrosswalk) {
      // On ignore tout : probablement un passage piéton / marquage au sol linéaire
      return [];
    }

    // 4) Sinon, on enlève seulement les grosses bandes horizontales isolées en bas
    return raw.filter(p => {
      const wNorm = p.width / imgW;
      const hNorm = p.height / imgH;
      const yNorm = p.y / imgH;
      const ratio = hNorm <= 1e-6 ? 999 : wNorm / hNorm;

      const isBigBand = (wNorm > 0.45 && ratio > 5.0 && yNorm > 0.55);
      return !isBigBand;
    });
  }

  // === 5. Gestion de la caméra ===
  async function startCamera() {
    try {
      stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "environment" },
        audio: false
      });
      video.srcObject = stream;
      infoDiv.textContent = "Caméra en direct. Clique sur 'Démarrer' pour analyser.";
      statusDiv.textContent = "";
    } catch (err) {
      console.error(err);
      infoDiv.textContent = "Impossible d'accéder à la caméra.";
      statusDiv.textContent = err.message;
    }
  }

  function stopCamera() {
    if (stream) {
      stream.getTracks().forEach(t => t.stop());
      stream = null;
    }
    video.srcObject = null;
  }

  // === 6. Boucle d'analyse (équivalent de ta boucle while + SKIP_FRAMES) ===
  async function processFrameLoop() {
    if (!video.videoWidth || !video.videoHeight) return;
    if (isBusy) return;
    isBusy = true;

    try {
      overlay.width = video.videoWidth;
      overlay.height = video.videoHeight;

      const tmpCanvas = document.createElement("canvas");
      tmpCanvas.width = video.videoWidth;
      tmpCanvas.height = video.videoHeight;
      const tmpCtx = tmpCanvas.getContext("2d");
      tmpCtx.drawImage(video, 0, 0, tmpCanvas.width, tmpCanvas.height);

      const dataURL = tmpCanvas.toDataURL("image/jpeg", 0.8);
      const base64Data = dataURL.split(",")[1];

      const json = await callWorkflowWithBase64(base64Data);
      const preds = findPredictions(json) || [];

      const imgW = tmpCanvas.width;
      const imgH = tmpCanvas.height;

      // --- FILTRE + ANTI-CLIGNOTEMENT ---
      let filtered = filterStairs(preds, imgW, imgH, MIN_CONF);

      if (filtered.length === 0) {
        // aucune détection sur cette frame → on garde les anciennes quelques frames
        if (persistenceCounter < persistenceFrames) {
          filtered = previousDetections;
          persistenceCounter++;
        } else {
          previousDetections = [];
        }
      } else {
        // on a des détections → on les mémorise
        previousDetections = filtered;
        persistenceCounter = 0;
      }

      ctx.clearRect(0, 0, overlay.width, overlay.height);
      ctx.lineWidth = 2;
      ctx.font = "14px Arial";

      let countTotal = 0;
      let countLoin = 0;
      let countMoyen = 0;
      let countProche = 0;

      for (const p of filtered) {
        const conf = p.confidence || 0.0;
        const x = p.x;
        const y = p.y;
        const w = p.width;
        const h = p.height;
        const cls = p.class || "stair";

        const x1 = Math.round(x - w / 2);
        const y1 = Math.round(y - h / 2);
        const x2 = Math.round(x + w / 2);
        const y2 = Math.round(y + h / 2);

        const cat = distanceCategory(h, imgH);

        countTotal++;
        if (cat === "loin") countLoin++;
        else if (cat === "moyen") countMoyen++;
        else countProche++;

        ctx.strokeStyle = "lime";
        ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);

        const label = `${cls} ${conf.toFixed(2)} ${cat}`;
        ctx.fillStyle = "lime";
        ctx.fillText(label, x1 + 2, Math.max(y1 - 4, 12));
      }

      const info = `Marches: ${countTotal} (loin:${countLoin} moy:${countMoyen} proche:${countProche})`;
      infoDiv.textContent = info;
      statusDiv.textContent = `Dernière mise à jour: ${new Date().toLocaleTimeString()}`;
    } catch (err) {
      console.error(err);
      statusDiv.textContent = "Erreur: " + err.message;
    } finally {
      isBusy = false;
    }
  }

  // === 7. Boutons Démarrer / Arrêter ===
  startBtn.addEventListener("click", () => {
    if (!stream) {
      startCamera().then(() => {
        intervalId = setInterval(processFrameLoop, FRAME_INTERVAL_MS);
        startBtn.disabled = true;
        stopBtn.disabled = false;
        infoDiv.textContent = "Analyse en cours…";
      });
    } else {
      intervalId = setInterval(processFrameLoop, FRAME_INTERVAL_MS);
      startBtn.disabled = true;
      stopBtn.disabled = false;
      infoDiv.textContent = "Analyse en cours…";
    }
  });

  stopBtn.addEventListener("click", () => {
    // on arrête la boucle d'analyse
    if (intervalId) {
      clearInterval(intervalId);
      intervalId = null;
    }

    // on coupe la caméra
    stopCamera();

    // on nettoie l'affichage
    ctx.clearRect(0, 0, overlay.width, overlay.height);
    infoDiv.textContent = "Caméra arrêtée.";
    statusDiv.textContent = "";

    // on réactive le bouton Démarrer
    startBtn.disabled = false;
    stopBtn.disabled = true;
  });

  // on prépare la caméra au chargement de la page
  window.addEventListener("load", () => {
    startCamera();
  });
</script>

</body>
</html>
